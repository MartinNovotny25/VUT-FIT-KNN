{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "from torch import nn\n",
        "import random\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from scipy.ndimage import distance_transform_bf\n",
        "from torchvision.transforms.functional import center_crop\n",
        "torch.set_grad_enabled(True)"
      ],
      "metadata": {
        "id": "XlAsh_kqbgbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Es7nL9AhaL6U"
      },
      "outputs": [],
      "source": [
        "#extract files.zip\n",
        "with zipfile.ZipFile('/content/drive/My Drive/orig_dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1PgSl-Ld9pTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_click(ground_truth, prediction):\n",
        "    prediction = prediction.astype(int)\n",
        "    gt = ground_truth.astype(int)\n",
        "    D_map = gt - prediction\n",
        "\n",
        "    D_plus = D_map.copy()\n",
        "    D_minus = D_map.copy()\n",
        "    D_plus[D_plus < 0] = 0 #D_plus are false-negative pixels\n",
        "    D_minus[D_minus > 0] = 0 #D_minus are false-positive pixels\n",
        "    D_minus = np.abs(D_minus)\n",
        "\n",
        "    #sum non zero elements of D_minus and D_plus\n",
        "    sum_D_minus = np.sum(D_minus)\n",
        "    sum_D_plus = np.sum(D_plus)\n",
        "\n",
        "\n",
        "    click_type = False\n",
        "    if(sum_D_minus > sum_D_plus):\n",
        "        click_type = False\n",
        "        selected_map = D_minus\n",
        "    else:\n",
        "        click_type = True\n",
        "        selected_map = D_plus\n",
        "\n",
        "    #get distances of each pixel to the nearest border\n",
        "    selected_map = selected_map.astype(np.uint8)\n",
        "    sel_map_transformed = cv2.distanceTransform(selected_map, cv2.DIST_L2, 5)\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    #this should only happen on perfect prediction\n",
        "    if(np.sum(sel_map_transformed) == 0):\n",
        "        return (-1, -1), click_type\n",
        "\n",
        "    #get probability map and flattened probablities for pixel selection\n",
        "    P_map = sel_map_transformed / (np.sum(sel_map_transformed))\n",
        "    flattened_probabilities = P_map.flatten()\n",
        "    # -----------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "    #select a random pixel based on the probabilities\n",
        "    random_pixel_index = np.random.choice(np.arange(len(flattened_probabilities)), p=flattened_probabilities)\n",
        "    random_pixel_2d_index = np.unravel_index(random_pixel_index, P_map.shape)\n",
        "    return random_pixel_2d_index, click_type"
      ],
      "metadata": {
        "id": "wCLJsQLzfbhS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional block which combines 2D convolution, batch normalization and ReLU activation into one."
      ],
      "metadata": {
        "id": "IqHZY8eyWlmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size=3,\n",
        "                 stride=1,\n",
        "                 padding=0):\n",
        "        super(CNNBlock, self).__init__()\n",
        "\n",
        "        self.seq_block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.seq_block(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "UEWKdbMUiaIY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block of N convolutional blocks (N = 3 for basic UNET)"
      ],
      "metadata": {
        "id": "5HAwzzflW0kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNBlocks(nn.Module):\n",
        "    def __init__(self,\n",
        "                 n_conv,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 padding):\n",
        "        super(CNNBlocks, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(n_conv):\n",
        "            self.layers.append(CNNBlock(in_channels, out_channels, padding=padding))\n",
        "            # after each convolution we set (next) in_channel to (previous) out_channels\n",
        "            in_channels = out_channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "dlKADweUigdx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder part of the UNET."
      ],
      "metadata": {
        "id": "B5PgyHIYXUAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 padding,\n",
        "                 downhill=4): #amount of steps in Encoder\n",
        "        super(Encoder, self).__init__()\n",
        "        self.enc_layers = nn.ModuleList()\n",
        "\n",
        "        #add a cnn block and a max pool layer for each step\n",
        "        for _ in range(downhill):\n",
        "            self.enc_layers += [\n",
        "                    CNNBlocks(n_conv=2, in_channels=in_channels, out_channels=out_channels, padding=padding),\n",
        "                    nn.MaxPool2d(2, 2)\n",
        "                ]\n",
        "            in_channels = out_channels #set the amount of input channels of the next step as the output of this step\n",
        "            out_channels *= 2 #double the amount of output channels for the next step\n",
        "\n",
        "        #depth of the last CNN block is doubled (bottleneck)\n",
        "        self.enc_layers.append(CNNBlocks(n_conv=2, in_channels=in_channels,\n",
        "                                         out_channels=out_channels, padding=padding))\n",
        "\n",
        "    def forward(self, x):\n",
        "        route_connection = []\n",
        "        for layer in self.enc_layers:\n",
        "            if isinstance(layer, CNNBlocks):\n",
        "                x = layer(x)\n",
        "                route_connection.append(x) #appending connections (horizontal arrows in UNET architecture)\n",
        "            else:\n",
        "                x = layer(x)\n",
        "        return x, route_connection"
      ],
      "metadata": {
        "id": "shDwOq5Siyeo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder part of the UNET"
      ],
      "metadata": {
        "id": "golJ59W3Ylrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 exit_channels,\n",
        "                 padding,\n",
        "                 uphill=4):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.exit_channels = exit_channels\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        for i in range(uphill):\n",
        "            self.layers += [\n",
        "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
        "                CNNBlocks(n_conv=2, in_channels=in_channels,\n",
        "                          out_channels=out_channels, padding=padding),\n",
        "            ]\n",
        "            #halving input and output channels on each step upwards\n",
        "            in_channels //= 2\n",
        "            out_channels //= 2\n",
        "\n",
        "        #one more convolution ath the end with kernel size 1\n",
        "        self.layers.append(\n",
        "            nn.Conv2d(in_channels, exit_channels, kernel_size=1, padding=padding),\n",
        "        )\n",
        "\n",
        "        #sigmoid output to turn logits into probabilities of pixels belonging to the final mask\n",
        "        self.layers.append(nn.Sigmoid())\n",
        "\n",
        "\n",
        "    def forward(self, x, routes_connection):\n",
        "        #pop the last route connection (this one was created for bottleneck and is useless)\n",
        "        routes_connection.pop(-1)\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, CNNBlocks):\n",
        "                #crop to make input and output dimensions match\n",
        "                routes_connection[-1] = center_crop(routes_connection[-1], x.shape[2])\n",
        "                #use concatenation for connections\n",
        "                x = torch.cat([x, routes_connection.pop(-1)], dim=1)\n",
        "                x = layer(x)\n",
        "            else:\n",
        "                x = layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "zxqMKK-ZjMVw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "UNET model class"
      ],
      "metadata": {
        "id": "Ji2AynPGaJm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 first_out_channels, #output of the first CNN Block\n",
        "                 exit_channels,\n",
        "                 downhill,\n",
        "                 padding=1\n",
        "                 ):\n",
        "        super(UNET, self).__init__()\n",
        "        self.encoder = Encoder(in_channels, first_out_channels, padding=padding, downhill=downhill)\n",
        "        self.decoder = Decoder(first_out_channels*(2**downhill), first_out_channels*(2**(downhill-1)),\n",
        "                               exit_channels, padding=padding, uphill=downhill)\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc_out, routes = self.encoder(x)\n",
        "        out = self.decoder(enc_out, routes)\n",
        "        return out"
      ],
      "metadata": {
        "id": "AbALTNp7jU1v"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class for loading an image dataset"
      ],
      "metadata": {
        "id": "rHW1aPu3aWnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, dataset_dir, mode, transform=None, target_transform=None, total_cnt=None):\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.image_data = [] #will store tuples of paths to image and label\n",
        "        for imgnum_dir in os.listdir(dataset_dir + \"/\" + mode + \"/\"):\n",
        "            img_dir = dataset_dir + \"/\" + mode + \"/\" + imgnum_dir + \"/img\"\n",
        "            label_dir = dataset_dir + \"/\" + mode + \"/\" + imgnum_dir + \"/label\"\n",
        "            for img in os.listdir(img_dir):\n",
        "                for label in os.listdir(label_dir):\n",
        "                    if label.startswith(img.split(\".\")[0]):\n",
        "                        self.image_data.append((os.path.join(img_dir, img), os.path.join(label_dir, label)))\n",
        "        #shuffle training data\n",
        "        random.shuffle(self.image_data)\n",
        "        if(total_cnt != None):\n",
        "            self.image_data = self.image_data[:total_cnt]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_data[idx][0])\n",
        "        label_path = os.path.join(self.image_data[idx][1])\n",
        "\n",
        "        image = read_image(img_path)\n",
        "        label = read_image(label_path)\n",
        "\n",
        "        image = image.numpy()\n",
        "        label = label.numpy()\n",
        "\n",
        "        image = np.transpose(image, (1, 2, 0))\n",
        "        label = np.transpose(label, (1, 2, 0))\n",
        "\n",
        "        #normalize from 0-255 to 0-1 float range\n",
        "        image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
        "        label = (label - np.min(label)) / (np.max(label) - np.min(label))\n",
        "\n",
        "        #insert first positive click\n",
        "        random_pixel_2d_index, click_type = get_random_click(label, np.zeros(label.shape))\n",
        "        pos_click_map = np.zeros(label.shape)\n",
        "        pos_click_map[random_pixel_2d_index] = 1\n",
        "        pos_click_map = gauss_filter(pos_click_map, 2)\n",
        "        pos_click_map = (pos_click_map - np.min(pos_click_map)) / (np.max(pos_click_map) - np.min(pos_click_map))\n",
        "        neg_click_map = np.zeros(label.shape)\n",
        "\n",
        "        #add dimension to pos_click_map\n",
        "        pos_click_map = np.expand_dims(pos_click_map, axis=2)\n",
        "        #concatenate channels\n",
        "        image = np.concatenate((image, pos_click_map, neg_click_map), axis=2)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "6qvuEVfTjXX8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gauss_filter(image, sigma):\n",
        "    return cv2.GaussianBlur(image, (0, 0), sigma)"
      ],
      "metadata": {
        "id": "3WkE4Xca03X6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomImageDataset(\"dataset\", \"training\", transform=transforms.ToTensor(), total_cnt=7500)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataset = CustomImageDataset(\"dataset\", \"testing\", transform=transforms.ToTensor(), total_cnt=2200)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
        "print(len(train_dataloader))\n",
        "print(len(val_dataloader))"
      ],
      "metadata": {
        "id": "ka1R6atGp0xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class diceloss(torch.nn.Module):\n",
        "    def init(self):\n",
        "        super(diceloss, self).init()\n",
        "    def forward(self,pred, label):\n",
        "       smooth = 1\n",
        "       iflat = pred.contiguous().view(-1)\n",
        "       tflat = label.contiguous().view(-1)\n",
        "       intersection = (iflat * tflat).sum()\n",
        "       A_sum = torch.sum(iflat * iflat)\n",
        "       B_sum = torch.sum(tflat * tflat)\n",
        "       return 1 - ((2. * intersection + smooth) / (A_sum + B_sum + smooth))"
      ],
      "metadata": {
        "id": "h1JEdbgM3hkA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_clicks_to_batch(input, pred, label, k, total_k, probabilistic_clicks=False):\n",
        "    click_probability = 1.0\n",
        "    if probabilistic_clicks:\n",
        "        click_probability = 1.0 - (float(k) / float(total_k))\n",
        "    #for each image in batch\n",
        "    pred = pred.permute(0, 2, 3, 1)\n",
        "    label = label.permute(0, 2, 3, 1)\n",
        "    for i in range(pred.shape[0]):\n",
        "        #get random click\n",
        "        if np.random.rand() > click_probability:\n",
        "            continue\n",
        "        #convert from tensor to numpy array (detaching is safe, we do not need gradients in this stage)\n",
        "        pred_np = pred[i].detach().cpu().numpy()\n",
        "        label_np = label[i].detach().cpu().numpy()\n",
        "        #turn pred and label from (W,H,1) to (W,H)\n",
        "        pred_np = pred_np[:,:,0]\n",
        "        label_np = label_np[:,:,0]\n",
        "        random_pixel_2d_index, click_type = get_random_click(label_np, pred_np)\n",
        "        #nowhere to place click\n",
        "        if(random_pixel_2d_index == (-1,-1)):\n",
        "            continue\n",
        "        pos_map = np.zeros(pred_np.shape)\n",
        "        neg_map = np.zeros(pred_np.shape)\n",
        "        if click_type:\n",
        "            pos_map[random_pixel_2d_index] = 1\n",
        "            pos_map = gauss_filter(pos_map, 2)\n",
        "            pos_map = (pos_map - np.min(pos_map)) / (np.max(pos_map) - np.min(pos_map))\n",
        "        else:\n",
        "            neg_map[random_pixel_2d_index] = 1\n",
        "            neg_map = gauss_filter(neg_map, 2)\n",
        "            neg_map = (neg_map - np.min(neg_map)) / (np.max(neg_map) - np.min(neg_map))\n",
        "\n",
        "        #get the second channel of the input image\n",
        "        input_pos_map = input[i][1].detach().cpu().numpy()\n",
        "        input_neg_map = input[i][2].detach().cpu().numpy()\n",
        "\n",
        "        #add the input maps and new click maps\n",
        "        input_pos_map = input_pos_map + pos_map\n",
        "        input_neg_map = input_neg_map + neg_map\n",
        "\n",
        "        #normalize the input maps\n",
        "        input_pos_map = (input_pos_map - np.min(input_pos_map)) / ((np.max(input_pos_map) - np.min(input_pos_map)) + 0.0000001) #small epsilon to avoi NaNs\n",
        "        input_neg_map = (input_neg_map - np.min(input_neg_map)) / ((np.max(input_neg_map) - np.min(input_neg_map)) + 0.0000001)\n",
        "\n",
        "        #add the new maps to the input\n",
        "        input[i][1] = torch.tensor(input_pos_map)\n",
        "        input[i][2] = torch.tensor(input_neg_map)\n",
        "    return input"
      ],
      "metadata": {
        "id": "omXcHj1BMqi-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_iou(pred, label):\n",
        "    pred = pred.detach().cpu().numpy()\n",
        "    label = label.detach().cpu().numpy()\n",
        "    intersection = np.logical_and(pred, label)\n",
        "    union = np.logical_or(pred, label)\n",
        "    iou = np.sum(intersection) / np.sum(union)\n",
        "    return iou"
      ],
      "metadata": {
        "id": "5itHOQj0TrIS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(dataloader, model, loss_fn, device, k):\n",
        "    size = len(dataloader)\n",
        "    avg_loss = 0\n",
        "    avg_iou = 0\n",
        "\n",
        "    avg_loss_1 = []\n",
        "    avg_loss_2 = []\n",
        "    avg_loss_5 = []\n",
        "    avg_loss_10 = []\n",
        "    avg_loss_15 = []\n",
        "    avg_iou_1 = []\n",
        "    avg_iou_2 = []\n",
        "    avg_iou_5 = []\n",
        "    avg_iou_10 = []\n",
        "    avg_iou_15 = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            X = X.permute(0, 3, 1, 2)\n",
        "            y = y.permute(0, 3, 1, 2)\n",
        "            X = X.float()\n",
        "            y = y > 0.5\n",
        "            y = y.float()\n",
        "\n",
        "            pred = model(X)\n",
        "            pred = center_crop(pred, y.shape[2])\n",
        "            loss = loss_fn(pred, y)\n",
        "\n",
        "            pred = pred > 0.5\n",
        "            avg_iou_1.append(get_iou(pred, y))\n",
        "            avg_loss_1.append(loss.item())\n",
        "\n",
        "\n",
        "            for i in range(k):\n",
        "                pred = model(X)\n",
        "                pred = center_crop(pred, y.shape[2])\n",
        "                pred = pred > 0.5\n",
        "                X = add_clicks_to_batch(X, pred, y, i, k, False)\n",
        "                pred = model(X)\n",
        "                pred = center_crop(pred, y.shape[2])\n",
        "                loss = loss_fn(pred, y)\n",
        "                if (i == 0):\n",
        "                    pred = pred > 0.5\n",
        "                    avg_iou_2.append(get_iou(pred, y))\n",
        "                    avg_loss_2.append(loss.item())\n",
        "                elif (i == 3):\n",
        "                    pred = pred > 0.5\n",
        "                    avg_iou_5.append(get_iou(pred, y))\n",
        "                    avg_loss_5.append(loss.item())\n",
        "                elif (i == 8):\n",
        "                    pred = pred > 0.5\n",
        "                    avg_iou_10.append(get_iou(pred, y))\n",
        "                    avg_loss_10.append(loss.item())\n",
        "                elif (i == 13):\n",
        "                    pred = pred > 0.5\n",
        "                    avg_iou_15.append(get_iou(pred, y))\n",
        "                    avg_loss_15.append(loss.item())\n",
        "\n",
        "\n",
        "\n",
        "    iou_total = [avg_iou_1, avg_iou_2, avg_iou_5,avg_iou_10, avg_iou_15]\n",
        "    loss_total = [avg_loss_1, avg_loss_2, avg_loss_5,avg_loss_10, avg_loss_15]\n",
        "\n",
        "    return iou_total, loss_total"
      ],
      "metadata": {
        "id": "kDPK-spsSKT0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "model = UNET(in_channels=3, first_out_channels=32, exit_channels=1, downhill=4)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/InterSegModelV1.pth\"))\n",
        "model.to(device)\n",
        "loss_fn = diceloss()\n",
        "\n",
        "model.eval()\n",
        "iou_total, loss_total = eval(val_dataloader, model, loss_fn, device, 15)\n",
        "size = len(val_dataloader)\n",
        "\n",
        "all_iou = []\n",
        "all_loss = []\n",
        "\n",
        "iou_sum = 0\n",
        "loss_sum = 0\n",
        "for i in range(len(iou_total)):\n",
        "  for x in range(len(iou_total[i])):\n",
        "    iou_sum += iou_total[i][x]\n",
        "    loss_sum += loss_total[i][x]\n",
        "  all_iou.append(iou_sum/len(iou_total[i]))\n",
        "  all_loss.append(loss_sum/len(loss_total[i]))\n",
        "  loss_sum = 0\n",
        "  iou_sum = 0\n",
        "\n",
        "print(iou_total)\n",
        "print(loss_total)\n",
        "\n",
        "print(all_iou)\n",
        "print(all_loss)\n",
        "\n",
        "\n",
        "plt.figure(figsize = (10,10))\n",
        "values =  [all_iou[0], all_iou[1],\n",
        "           all_iou[2], all_iou[3],\n",
        "           all_iou[4]]\n",
        "\n",
        "labels = ['1', '2', '5', '10', '15']\n",
        "colors = ['green', 'red', 'cyan', 'magenta', 'yellow']\n",
        "plt.ylim(0, 1)\n",
        "for i, (label, value) in enumerate(zip(labels, values)):\n",
        "    plt.bar(i, value, align='center', color=colors[i], label=label, width=0.5)\n",
        "    plt.text(i, value - 0.04, f'{value:.2f}', ha='center')\n",
        "\n",
        "plt.xticks(range(len(labels)), labels)\n",
        "plt.xlabel('Number of clicks')\n",
        "plt.ylabel('Average IoU')\n",
        "plt.title('Average IoUs per number of clicks')\n",
        "\n",
        "# Display the plot\n",
        "plt.savefig('average_iou.png')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h4pg1YRE57dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#into ope plot display loss of training and validation\n",
        "plt.figure()\n",
        "plt.plot(train_loss_record, label=\"Training Loss\")\n",
        "plt.plot(val_loss_record, label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Loss\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train_iou_record, label=\"Training IoU\")\n",
        "plt.plot(val_iou_record, label=\"Validation IoU\")\n",
        "plt.legend()\n",
        "plt.title(\"IoU\")"
      ],
      "metadata": {
        "id": "NGiYw6okWxZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visual_eval(dataloader, model, device, k):\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            X = X.permute(0, 3, 1, 2)\n",
        "            y = y.permute(0, 3, 1, 2)\n",
        "            X = X.float()\n",
        "            y = y > 0.5\n",
        "            y = y.float()\n",
        "\n",
        "            pred = model(X)\n",
        "            pred = center_crop(pred, y.shape[2])\n",
        "            pred = pred > 0.5\n",
        "\n",
        "            for i in range(16):\n",
        "                if i >= pred.shape[0]:\n",
        "                    break\n",
        "                #print image, prediction and ground truth in one picture\n",
        "                print_img = X[i].permute(1,2,0)\n",
        "                print_img = print_img.clone().detach().cpu().numpy()\n",
        "                print_pred = pred[i].permute(1,2,0)\n",
        "                print_pred = print_pred.clone().detach().cpu().numpy()\n",
        "                print_gt = y[i].permute(1,2,0)\n",
        "                print_gt = print_gt.clone().detach().cpu().numpy()\n",
        "\n",
        "                print_gt = y[i].permute(1,2,0)\n",
        "                print_gt = print_gt.clone().detach().cpu().numpy()\n",
        "                plt.subplot(4,4,i+1)\n",
        "                plt.axis('off')\n",
        "                #make images as close to each other as possible\n",
        "                plt.subplots_adjust(wspace=0, hspace=0)\n",
        "                plt.imshow(print_img)\n",
        "                plt.imshow(print_pred, alpha=0.4, cmap='hot', interpolation=\"spline16\")\n",
        "            print(\"Click 1\")\n",
        "            plt.show()\n",
        "            avg_iou = get_iou(pred, y)\n",
        "            print(avg_iou)\n",
        "\n",
        "            for i in range(k):\n",
        "                pred = model(X)\n",
        "                pred = center_crop(pred, y.shape[2])\n",
        "                pred = pred > 0.5\n",
        "                X = add_clicks_to_batch(X, pred, y, i, k, False)\n",
        "                pred = model(X)\n",
        "                pred = center_crop(pred, y.shape[2])\n",
        "                pred = pred > 0.5\n",
        "                plt.figure(figsize=(10,10))\n",
        "                if i == 0 or i == 3 or i == 8 or i == 13:\n",
        "                  print(\"Click: \", i+2)\n",
        "                  for i in range(16):\n",
        "                      #if pred is out of range, break\n",
        "                      if i >= pred.shape[0]:\n",
        "                          break\n",
        "                      #print image, prediction and ground truth in one picture\n",
        "                      print_img = X[i].permute(1,2,0)\n",
        "                      print_img = print_img.clone().detach().cpu().numpy()\n",
        "                      print_pred = pred[i].permute(1,2,0)\n",
        "                      print_pred = print_pred.clone().detach().cpu().numpy()\n",
        "                      print_gt = y[i].permute(1,2,0)\n",
        "                      print_gt = print_gt.clone().detach().cpu().numpy()\n",
        "\n",
        "                      print_gt = y[i].permute(1,2,0)\n",
        "                      print_gt = print_gt.clone().detach().cpu().numpy()\n",
        "                      plt.subplot(4,4,i+1)\n",
        "                      plt.axis('off')\n",
        "                      #make images as close to each other as possible\n",
        "                      plt.subplots_adjust(wspace=0, hspace=0)\n",
        "                      plt.imshow(print_img)\n",
        "                      plt.imshow(print_pred, alpha=0.4, cmap='hot', interpolation=\"spline16\")\n",
        "                      #plt.imshow(print_gt, alpha=0.2, cmap=\"Blues\")\n",
        "                  plt.show()\n",
        "                  avg_iou = get_iou(pred, y)\n",
        "                  print(avg_iou)\n",
        "                  print(\"-----------------\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IK_8yJJQlXoz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visual_eval(val_dataloader, model, device, 14)"
      ],
      "metadata": {
        "id": "jLfNrm3FljFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/InterSegModelV1.pth /content/drive/MyDrive/InterSegModelV1.pth"
      ],
      "metadata": {
        "id": "6RUU1giN12wA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}